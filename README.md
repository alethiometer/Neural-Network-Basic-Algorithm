# Neural Network: Basic Algorithm

The program implements JavaScript as a personal tutorial on basic forward and backward propagation.

## Overview

This program serves to represent a basic neural network using supervised inputs 0.05 and 0.10. 

The numerical values of the inputs are manipulated by the weights as the input values pass from the hidden layer to the output layer. 

The goal is to produce outputs 0.01 and 0.99, numbers heuristically close to 0 and 1, and thus able to represent 0 or false, and 1 or true.

There will be two input neurons in the input layer, two hidden neurons in the hidden layer, and two output neurons in the output layer.

## Note

Certain numerical values are used as the starting inputs and weights as used by Matt Mazur in his backpropagation tutorial. 

However, these values are only used to ensure every formula is written correctly and the results are accurate, so that it may be reassured this program functions properly. All algorithms and abstracts were independently developed so that I could arrive at the desired targets.
